{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb2f6d66",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962c4d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sugestão: ceontrar todos os imports utilizados no código aqui\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import (ensemble, preprocessing, tree)\n",
    "from sklearn.metrics import(auc, confusion_matrix, roc_auc_score,roc_curve)\n",
    "from sklearn.model_selection import (train_test_split, StratifiedKFold)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "# Sugiro remover esses abaixo\n",
    "\n",
    "from yellowbrick.classifier import ConfusionMatrix #vou chamar quando for usar. Rolou um BO no início. Pois, precisei comendar todas as bibliotecas do yellowbrick até realmente usar\n",
    "from yellowbrick.classifier.rocauc import roc_auc\n",
    "from yellowbrick.model_selection import LearningCurve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd39393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee6e4bd",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1b9ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregando o dataset\n",
    "df = pd.read_csv('https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv')\n",
    "display(df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cde7e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe76e3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b00263",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path='data/'\n",
    "os.makedirs('data', exist_ok=True) \n",
    "os.makedirs('data/processed', exist_ok=True)\n",
    "os.makedirs('data/preprocessed', exist_ok=True)    \n",
    "\n",
    "df.to_csv(os.path.join(dir_path, 'raw_data.csv'), index=False) #tbm faremos o mesmo quando o df for limpo ou fracionado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e397fc70",
   "metadata": {},
   "source": [
    "# Estudo para limpeza dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e9ff2a",
   "metadata": {},
   "source": [
    "Aqui queremos trabalho sobre os NaNs ou outliers ou dados inconsistentes. Assim como queremos ermover colunas que possam gerar algum data leakege. Tbm vamos criar colunas dummy ('pd.get_dummies')caso precisemos.\n",
    "\n",
    "    Data leakage ocorre quando informações do conjunto de dados de teste ou validação vazam para o conjunto de treinamento durante o pré-processamento ou modelagem, ou quando informações do target vazam para as features.\n",
    "\n",
    "Nesse processo vamos utilizar duas bibliotecas do pandas\n",
    "\n",
    "    pandas_profiling\n",
    "    pandas_profiling.ProfileReport(df) Para gerar relatórios em notebooks para vermos detalhes estatísticos descritivos e dos quantis, além de histogramas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826685a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Análise Estatística Descritiva\n",
    "print(\"--- Estatísticas Descritivas ---\")\n",
    "print(df.describe())\n",
    "\n",
    "# 2. Verificação de valores nulos\n",
    "print(\"\\n--- Valores Ausentes ---\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# --- CONFIGURAÇÃO VISUAL ---\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Histograma de Idades\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.histplot(df['Age'].dropna(), bins=10, kde=True, color='skyblue')\n",
    "plt.title('Distribuição de Idade')\n",
    "\n",
    "# Plot 2: Boxplot de Tarifa por Classe (Identificação de Outliers)\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(x='Pclass', y='Fare', data=df, palette='Set2')\n",
    "plt.title('Tarifa por Classe (Boxplot)')\n",
    "\n",
    "# Plot 3: Taxa de Sobrevivência por Sexo\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.barplot(x='Sex', y='Survived', data=df, ci=None, palette='viridis')\n",
    "plt.title('Taxa de Sobrevivência por Sexo')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585166f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://buildml.substack.com/p/crash-course-to-crack-machine-learning-c5b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
